{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-Qtoca7Jf3w"
   },
   "outputs": [],
   "source": [
    "#CITATION Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.\n",
    "# from chapter 3 NLTK https://www.nltk.org/book/ch03.html\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.book import *\n",
    "#nltk.download() #may not need this again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = '/Users/lawrence/'\n",
    "#print (os.listdir(directory))\n",
    "Corpus_Pdfs=\"\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(directory, filename)) as f:\n",
    "            content=f.read()\n",
    "            Corpus_Pdfs=Corpus_Pdfs + content\n",
    "            print ('\\n\\nFile',filename)\n",
    "            f.close()\n",
    "print (repr(Corpus_Pdfs[1:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTION 1: RAW TEXT TO WORD TOKENS TO PROCESSED. PROCESSED TO TAGGED TO TEXT (list)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cns-tast-gd-4.2.pdf', 'Title', 'of', 'document', 'OFFICIAL', 'ONR', 'GUIDE', 'SUPPLIER', 'CAPABILITY', 'Document']\n",
      "['cns-tast-gd-4.2.pdf', 'Title', 'document', 'OFFICIAL', 'ONR', 'GUIDE', 'SUPPLIER', 'CAPABILITY', 'Document', 'Type']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(Corpus_Pdfs)\n",
    "print (tokens[:10])\n",
    "punctuation = list(string.punctuation)\n",
    "stopWords = set(stopwords.words('english'))\n",
    "stopWords.add('...') #using add because it is set.add()\n",
    "processed_tokens = []\n",
    "for w in tokens:\n",
    "    if w.lower()not in stopWords and w not in punctuation:\n",
    "        processed_tokens.append(w)\n",
    "print(processed_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cns-tast-gd-4.2.pdf', 'JJ'), ('Title', 'NNP'), ('document', 'NN'), ('OFFICIAL', 'NNP'), ('ONR', 'NNP'), ('GUIDE', 'NNP'), ('SUPPLIER', 'NNP'), ('CAPABILITY', 'NNP'), ('Document', 'NNP'), ('Type', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(processed_tokens)\n",
    "print (tagged[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print (text[100:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTION 2: RAW TEXT TO SENTENCES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(Corpus_Pdfs)\n",
    "print (sents[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTITIES** from tagged word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged[1:100])\n",
    "print (entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCORDANCE AND COMMON CONTEXTS AND DISPERSION OF TERMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance(\"old\", width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_of “_”\n"
     ]
    }
   ],
   "source": [
    "text.common_contexts([\"process\",\"guidance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.dispersion_plot([\"guidance\", \"purpose\", \"supply\"])  #still gives a result despite warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTIONAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate(length=100, text_seed=None, random_seed=42)\n",
    "text.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo of parsing, but not for this file as not parsed\n",
    ">>> from nltk.corpus import treebank\n",
    ">>> t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    ">>> t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIZING\n",
    "num_lines =0\n",
    "num_words =0\n",
    "num_chars =0\n",
    "\n",
    "for line in Corpus_Pdfs:\n",
    "    words = line.split()\n",
    "\n",
    "    num_lines += 1\n",
    "    num_words += len(words)\n",
    "    num_chars += len(line)\n",
    "\n",
    "print (\"numbers of words\", num_words)\n",
    "print(\"number of lines\", num_lines)\n",
    "print(\"number of chars\", num_chars)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "201909usingNTLK.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
