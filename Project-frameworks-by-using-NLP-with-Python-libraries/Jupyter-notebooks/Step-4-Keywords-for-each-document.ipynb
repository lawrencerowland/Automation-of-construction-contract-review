{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover Keywords for each document\n",
    "\n",
    "|**[Overview](#Overview)** |**[Installation](#Installation)||**[Prior-steps](#Prior-steps)**|**[How-to-use](#How-to-use)**|**[Next-steps](#Next-steps)**|\n",
    "\n",
    "# Overview\n",
    "\n",
    "This prints out a keyword for each document, collected together in the [interim results folder](https://github.com/lawrencerowland/Data-Model-for-Project-Frameworks/tree/master/Project-frameworks-by-using-NLP-with-Python-libraries/Interim-results).\n",
    "\n",
    "As seen in the outputs, for example, for the first document, keywords around security and commissioning are proposed. \n",
    "\n",
    "And for construction assurance, the focus is on design, construction, safety, contractors and material.\n",
    "\n",
    "# Installation\n",
    "\n",
    "Check installation has been made, as per the [READme](https://github.com/lawrencerowland/Data-Model-for-Project-Frameworks/blob/master/Project-frameworks-by-using-NLP-with-Python-libraries/README.md)\n",
    "\n",
    "# Prior steps\n",
    "None of the steps 1-3 are needed in order to generate these keywords.\n",
    "\n",
    "But to generate keywords of new documents, review these steps to see which you require.\n",
    "\n",
    "# How-to-use\n",
    "\n",
    "## Import Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Directory to find the portfolio text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import os\n",
    "directory = '/Users/lawrence/Documents/GitHub/Data-Model-for-Project-Frameworks/Nuclear-project-data-for-use-in-generating-example-frameworks'\n",
    "# Change directory location for your particular set-up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File Commissioning-of-security-systems-and-infrastructure-cns-tast-gd-4.4.pdf.txt\n",
      "Keywords: Commissioning-of-security-systems-and-infrastructure-cns-tast-gd-4.4.pdf.txtSummary\n",
      "security\n",
      "securely\n",
      "secure\n",
      "commissioning\n",
      "commissioned\n",
      "nuclear\n",
      "onr\n",
      "reference\n",
      "references\n",
      "refer\n",
      "refers\n",
      "document\n",
      "documentation\n",
      "documents\n",
      "regulation\n",
      "regulations\n",
      "regulates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Keywords_per_document =[]\n",
    "Keywords_per_document_as_string=\"\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(directory, filename)) as f:\n",
    "            \n",
    "            content = f.read()\n",
    "            \n",
    "            key_words=(filename+'Summary\\n'+keywords(content, ratio=0.02)+'\\n')\n",
    "            \n",
    "            print ('\\nFile',filename)\n",
    "            print ('Keywords:',key_words)\n",
    "            \n",
    "            Keywords_per_document.append(key_words)\n",
    "            Keywords_per_document_as_string+=(key_words)\n",
    "    \n",
    "            f.close()\n",
    "# Adjust the ratio of keywords to total content size if required. \n",
    "#There are also optional input parameters to change lemmatization, word-splitting and stemming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results as interim file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory= \"/Users/lawrence/Documents/GitHub/Data-Model-for-Project-Frameworks/Project-frameworks-by-using-NLP-with-Python-libraries/Interim-results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"Keyword_per_document\"\n",
    "f=open(directory+filename+\".txt\",\"w+\")  \n",
    "f.write(Keywords_per_document_as_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next-steps\n",
    "Progress to Step 5 (creating one single library of all documents) (xx) or return to the main sequence of steps (xx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
