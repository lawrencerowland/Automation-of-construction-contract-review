{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9 xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**[Overview](#Overview)** |**[Installation](#Installation)||**[Prior-steps](#Prior-steps)**|**[How-to-use](#How-to-use)**|**[Next-steps](#Next-steps)**|**[Acknowledgements](#Acknowledgments)**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This takes the library submitted. \n",
    "\n",
    "It creates a Bag of Words (CBOW) model, which is a vector representation of each document, with as many dimensions as there are frequent words in the library. \n",
    "\n",
    "This is not very useful for document comparison in itself.  So CBOW is transformed into a TF-IDF model. \n",
    "\n",
    "This model is saved so that it can be applied later, to:\n",
    "- directly run similarity queries between documents\n",
    "- create a topic model (LSI)\n",
    "A index is also saved, of the current library, in TFIDF format, for the future similarity queries within the current library. \n",
    "\n",
    "\n",
    "# How-to-use\n",
    "\n",
    "# Installation\n",
    "\n",
    "Check installation has been made, as per the [READme](https://github.com/lawrencerowland/Data-Model-for-Project-Frameworks/blob/master/Project-frameworks-by-using-NLP-with-Python-libraries/README.md)\n",
    "\n",
    "## Prior-steps\n",
    "Step 5\n",
    "# How-to-use\n",
    "\n",
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Whole library with json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import os\n",
    "directory= \"/Users/lawrence/Documents/GitHub/Data-Model-for-Project-Frameworks/Project-frameworks-by-using-NLP-with-Python-libraries/Interim-results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import json\n",
    "with open(directory+\"Corpus_as_list.json\", \"r\") as read_file:\n",
    "      Corpus_as_list= json.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify tokens and make-up a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common words and tokenize\n",
    "# Here we can add in some odd words we find in the output, or use the NLTK list\n",
    "stoplist = set('for a of the and to in \\uf06e  â€¢ \\uf0b7 \\uf0b7 \\uf06e uf09 \\uf09f'.split())\n",
    "Tokens_in_Corpus = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in Corpus_as_list]\n",
    "# This saves tokens as a list, one entry per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in Tokens_in_Corpus:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "Frequent_Tokens_in_Corpus= [[token for token in text if frequency[token] > 1] for text in Tokens_in_Corpus]\n",
    "# again tokens as a list, one entry per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint  # pretty-printer\n",
    "pprint(Frequent_Tokens_in_Corpus[16]) #these slices of lists go up to before the higher number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary, save it, then view map from ids to dictionary\n",
    "dictionary = corpora.Dictionary(Frequent_Tokens_in_Corpus)\n",
    "dictionary.save(directory+'Library.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary,\"\\n\\n\")\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We apply the BOW model back to the current library\n",
    "\n",
    "i.e. we now create recreate each document in our portfolio library as a list of vectors.\n",
    "However we dont get good results for similarity just from a bag of words model in itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ie. a list of a list. For each document, we have a list of word frequency for each dictionary item\n",
    "Corpus_as_BOW = [dictionary.doc2bow(text) for text in Frequent_Tokens_in_Corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory+\"Corpus_as_BOW.json\", \"w\") as write_file:\n",
    "    json.dump(Corpus_as_BOW, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "for c in Corpus_as_BOW:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE TF-IDF MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Gensim's Quick start [tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html#sphx-glr-auto-examples-core-run-topics-and-transformations-py). \n",
    "\"Now that we have vectorized our corpus we can begin to transform it using models. We use model as an abstract term referring to a transformation from one document representation to another. In gensim documents are represented as vectors so a model can be thought of as a transformation between two vector spaces. The details of this transformation are learned from the training corpus.\"\n",
    "\n",
    "One simple example of a model is tf-idf. The tf-idf model transforms vectors from the bag-of-words representation to a vector space where the frequency counts are weighted according to the relative rarity of each word in the corpus.\n",
    "Let's initialize the tf-idf model, training it on our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_MODEL= models.TfidfModel(Corpus_as_BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"From now on, tfidf is treated as a read-only object that can be used to convert any vector from the old representation (bag-of-words integer counts) to the new representation (TfIdf real-valued weights):\"\n",
    "\n",
    "Applying TfIDF model back onto the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_MODEL.save(directory+'model-from-input-library.tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ready for Cosine similarity\n",
    "This saves a representation of the current library (under TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(Corpus_as_TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.save(directory+'Index_for_corpus_for_similarities.index')\n",
    "index = similarities.MatrixSimilarity.load(directory+'Index_for_corpus_for_similarities.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next-steps\n",
    "Go to Step 10 to understand similarities:\n",
    "- across the whole library\n",
    "- for new documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postscript (saving model as temporary file)\n",
    "The model is currently being saved in the Results folder - but the below is an alternative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist the model\n",
    "import tempfile\n",
    "with tempfile.NamedTemporaryFile(prefix='model-', suffix='.tfidf', delete=False) as tmp:\n",
    "    TFIDF_MODEL.save(tmp.name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_TFIDF_model = models.TfidfModel.load(tmp.name)\n",
    "os.unlink(tmp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments\n",
    "This is extensively taken From Gensim's Quick start [tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html#sphx-glr-auto-examples-core-run-topics-and-transformations-py). All that has been done has been to apply it to the particular document library submitted in this Github folder, in this case, to ONR. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
