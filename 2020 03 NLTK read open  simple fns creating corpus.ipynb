{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-Qtoca7Jf3w"
   },
   "outputs": [],
   "source": [
    "#CITATION Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.\n",
    "# from chapter 3 NLTK https://www.nltk.org/book/ch03.html\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-Qtoca7Jf3w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#may not need this again\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RC4eAdQuje3W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin=open(\"2019_08_Marvin1_without_labels_or_heading.csv\")\n",
    "# ANY PROBLEMS WITH OPEN\n",
    "# newline conventions which are different for different operating systems. \n",
    "#The built-in open() function has a second parameter for controlling how the file is opened\n",
    "#'r' means to open the file for reading (the default)\n",
    "#'U' stands for \"Universal\", which lets us ignore the different conventions used for marking newlines.\n",
    "# though apparently U is deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"HAROLD MARCH, the rising reviewer and social critic, was walking vigorously across a great tableland of moors and commons, the horizon of which was fringed with the far-off woods of the famous estate of Torwood Park.\"\n",
      "\"A special program at the planetarium on the campus of nearby Butler University was the Barnetts’ turning point. A rapt Jake stunned the audience with an astute question about Mars’ moons, and on the drive home, couldn’t stop talking about the solar system. Jake “hadn’t been missing after all,” she realized, just because he was unreachable. Unhindered, he had been busy working: His repetitive behavior, much as some autism researchers have speculated, reflected detail-oriented curiosity rather than being merely a self-soothing habit. “Rage to master” was a relevant phrase coined by another psychologist, Ellen Winner, who concluded that a fiercely self-propelled drive was what set a true prodigy apart from a super-industrious high-achiever. “Nobody was telling Jake how to learn,” Kristine wrote, “because nobody thought he could. In that way, autism had given Jake a bizarre gift.”\"\n",
      "1\n",
      "“It’s empathy. It’s respect for the human experience. It’s being aware of the space you\n"
     ]
    }
   ],
   "source": [
    "raw=marvin.read()\n",
    "print (raw[:1200])\n",
    "# ANY PROBLEMS WITH READ\n",
    "#read() method creates a string with the contents of the entire file\n",
    "# the '\\n' characters are newlines (pressing Enter)\n",
    "#looks like I have to run read straight after open: sometimes it doesnt work otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or can also read a file one line at a time using a for loop:\n",
    "f = open(\"2019_08_Marvin1_without_labels_or_heading.csv\", 'r')\n",
    "for line in f:\n",
    "    print(line.strip())\n",
    "    #Here we use the strip() method to remove the newline character at the end of the input line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'HAROLD', 'MARCH', ',', 'the', 'rising', 'reviewer', 'and', 'social', 'critic']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print (tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', '``'), ('HAROLD', 'NNP'), ('MARCH', 'NNP'), (',', ','), ('the', 'DT'), ('rising', 'VBG'), ('reviewer', 'NN'), ('and', 'CC'), ('social', 'JJ'), ('critic', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "print (tagged[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "print (entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo of parsing, but not for this file as not parsed\n",
    ">>> from nltk.corpus import treebank\n",
    ">>> t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    ">>> t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: `` HAROLD MARCH , the rising reviewer and...>\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"HAROLD MARCH, the rising reviewer and social critic, was walking vigorously across a great tableland of moors and commons, the horizon of which was fringed with the far-off woods of the famous estate of Torwood Park.\"', '\"A special program at the planetarium on the campus of nearby Butler University was the Barnetts’ turning point.']\n"
     ]
    }
   ],
   "source": [
    "sents = nltk.sent_tokenize(raw)\n",
    "print (sents[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.concordance(\"old\", width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No common contexts were found\n"
     ]
    }
   ],
   "source": [
    "text.common_contexts([\"man\",\"person\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " text.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate(length=100, text_seed=None, random_seed=42)\n",
    "text.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating corpus\n",
    "#Whatever the location, set this to be the value of corpus_root [1].\n",
    "#The second parameter of the PlaintextCorpusReader initializer [2] can be a list of fileids\n",
    "#...like ['a.txt', 'test/b.txt'], or a pattern that matches all fileids, like '[abc]/.*\\.txt' \n",
    "#(see 3.4 for information about regular expressions).\n",
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = 'newcorpus/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mycorpus = PlaintextCorpusReader(corpus_root, '.*') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['201906_kindle_LR.txt',\n",
       " '2019_08_Marvin1_without_labels_or_heading_orwidgets.txt']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mycorpus.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Highlight', '\"', 'Come', ',', 'stop', 'inflaming', 'us', 'both', 'with', 'your', 'appeals', '.', 'I', 'set', 'sail', 'for', 'Italy', '—', 'all', 'against']\n"
     ]
    }
   ],
   "source": [
    "#the full text of the corpus as words\n",
    "text=Mycorpus.words()\n",
    "print (text[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598799"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'set', 'sail', 'for', 'Italy', '—', 'all', 'against', 'my', 'will', '.”', 'Even', 'from', 'the', 'start', 'of', 'his', 'declaration', ',', 'she', 'has', 'glared', 'at', 'him', 'askance', ',', 'her', 'eyes', 'roving', 'over', 'him', ',', 'head', 'to', 'foot', ',', 'with', 'a', 'look', 'of', 'stony', '\"', 'Wars', 'and', 'a', 'man', 'I', '\"', 'its', 'leafy', 'crest', 'showers', 'across', 'the', 'ground', 'but', 'it', 'clings', 'firm', 'to', 'its', 'rock', ',', '560', 'its', 'roots', 'stretching', 'as', 'deep', 'into', 'the', 'dark', 'world', 'below', 'as', 'its', 'crown', 'goes', 'towering', 'toward', 'the', 'gales', 'of', 'heaven', '—', 'so', 'firm', 'the', 'hero', 'stands', ':', 'buffeted', 'left', 'and', 'right', 'by', 'storms', 'of', 'appeals', ',', 'he', 'takes', 'the', 'full', 'force', 'of', 'love', 'and', 'suffering', 'deep', 'in', 'his', 'great', 'heart', '.'], ['His', 'will', 'stands', 'unmoved', '.']]\n"
     ]
    }
   ],
   "source": [
    "#the full text of the corpus as sentences\n",
    "text1 = Mycorpus.sents()\n",
    "print (text1[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing to see if I can do normal corpus functions to my corpus\n",
    "#these one are okay\n",
    "tagged = nltk.pos_tag(text)\n",
    "print (tagged [1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "print (entities [1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 26 36 201906_kindle_LR.txt\n",
      "5 30 6 2019_08_Marvin1_without_labels_or_heading_orwidgets.txt\n"
     ]
    }
   ],
   "source": [
    "#showing how to access all texts in a corpus\n",
    "for fileid in Mycorpus.fileids():\n",
    "...     num_chars = len(Mycorpus.raw(fileid)) \n",
    "...     num_words = len(Mycorpus.words(fileid))\n",
    "...     num_sents = len(Mycorpus.sents(fileid))\n",
    "...     num_vocab = len(set(w.lower() for w in Mycorpus.words(fileid)))\n",
    "...     print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We called him Tortoise because he taught us .'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from lists to strings\n",
    "silly = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']\n",
    "' '.join(silly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "201909usingNTLK.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "larry_kernel",
   "language": "python",
   "name": "larry_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
