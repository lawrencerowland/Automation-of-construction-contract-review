{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Here', 'are', 'two', 'sentences', '.']\n"
     ]
    }
   ],
   "source": [
    "#Process text\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Hello, world. Here are two sentences.\")\n",
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peach\n",
      "emoji\n",
      "üçë\n",
      "outranking eggplant\n",
      "Peach emoji\n",
      "Peach is the superior emoji.\n"
     ]
    }
   ],
   "source": [
    "#get tokens, noun chunks and sentences\n",
    "doc = nlp(\"Peach emoji is where it has always been. Peach is the superior \"\n",
    "          \"emoji. It's outranking eggplant üçë \")\n",
    "print(doc[0].text)          # 'Peach'\n",
    "print(doc[1].text)          # 'emoji'\n",
    "print(doc[-1].text)         # 'üçë'\n",
    "print(doc[17:19].text)      # 'outranking eggplant'\n",
    "\n",
    "noun_chunks = list(doc.noun_chunks)\n",
    "print(noun_chunks[0].text)  # 'Peach emoji'\n",
    "\n",
    "sentences = list(doc.sents)\n",
    "assert len(sentences) == 3\n",
    "print(sentences[1].text)    # 'Peach is the superior emoji.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-grained POS tag PROPN 96\n",
      "Coarse-grained POS tag NNP 15794550382381185553\n",
      "Word shape Xxxxx 16072095006890171862\n",
      "Alphabetic characters? True\n",
      "Punctuation mark? False\n",
      "Digit? False\n",
      "Like a number? True\n",
      "Like an email address? False\n"
     ]
    }
   ],
   "source": [
    "#get POS tags and flags\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "apple = doc[0]\n",
    "print(\"Fine-grained POS tag\", apple.pos_, apple.pos)\n",
    "print(\"Coarse-grained POS tag\", apple.tag_, apple.tag)\n",
    "print(\"Word shape\", apple.shape_, apple.shape)\n",
    "print(\"Alphabetic characters?\", apple.is_alpha)\n",
    "print(\"Punctuation mark?\", apple.is_punct)\n",
    "\n",
    "billion = doc[10]\n",
    "print(\"Digit?\", billion.is_digit)\n",
    "print(\"Like a number?\", billion.like_num)\n",
    "print(\"Like an email address?\", billion.like_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3197928453018144401 coffee\n",
      "3197928453018144401 3197928453018144401\n",
      "coffee coffee\n",
      "3073001599257881079 beer\n",
      "18234233413267120783 ü¶Ñ\n"
     ]
    }
   ],
   "source": [
    "#use hash values for any string, building up a vocabulary\n",
    "doc = nlp(\"I love coffee\")\n",
    "\n",
    "coffee_hash = nlp.vocab.strings[\"coffee\"]  # 3197928453018144401\n",
    "coffee_text = nlp.vocab.strings[coffee_hash]  # 'coffee'\n",
    "print(coffee_hash, coffee_text)\n",
    "print(doc[2].orth, coffee_hash)  # 3197928453018144401\n",
    "print(doc[2].text, coffee_text)  # 'coffee'\n",
    "\n",
    "beer_hash = doc.vocab.strings.add(\"beer\")  # 3073001599257881079\n",
    "beer_text = doc.vocab.strings[beer_hash]  # 'beer'\n",
    "print(beer_hash, beer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Francisco 0 13 GPE\n",
      "FB 0 2 ORG\n"
     ]
    }
   ],
   "source": [
    "#recognise and update named entities i.e. add an entity\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"San Francisco considers banning sidewalk delivery robots\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "doc = nlp(\"FB is hiring a new VP of global policy\")\n",
    "doc.ents = [Span(doc, 0, 1, label=\"ORG\")]\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"15859a115bd74a16983ee8c7dfb8ef64-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-15859a115bd74a16983ee8c7dfb8ef64-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-15859a115bd74a16983ee8c7dfb8ef64-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-15859a115bd74a16983ee8c7dfb8ef64-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-15859a115bd74a16983ee8c7dfb8ef64-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-15859a115bd74a16983ee8c7dfb8ef64-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-15859a115bd74a16983ee8c7dfb8ef64-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " Thrun started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#view a dependency parser\n",
    "# i seem to have to stop this for it to print out\n",
    "from spacy import displacy\n",
    "\n",
    "doc_dep = nlp(\"This is a sentence.\")\n",
    "displacy.render(doc_dep, style=\"dep\")\n",
    "\n",
    "doc_ent = nlp(\"When Sebastian Thrun started working on self-driving cars at Google \"\n",
    "              \"in 2007, few people outside of the company took him seriously.\")\n",
    "displacy.render(doc_ent, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple <-> banana 0.47310075\n",
      "pasta <-> hippo 0.36954373\n",
      "True True True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/.pyenv/versions/3.8.1/lib/python3.8/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  return _run_code(code, main_globals, None,\n",
      "/Users/lawrence/.pyenv/versions/3.8.1/lib/python3.8/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  return _run_code(code, main_globals, None,\n"
     ]
    }
   ],
   "source": [
    "#For the best results, this example should use the the en_vectors_web_lg model -as the small model doesnt have all the stuff\n",
    "doc = nlp(\"Apple and banana are similar. Pasta and hippo aren't.\")\n",
    "\n",
    "apple = doc[0]\n",
    "banana = doc[2]\n",
    "pasta = doc[6]\n",
    "hippo = doc[8]\n",
    "\n",
    "print(\"apple <-> banana\", apple.similarity(banana))\n",
    "print(\"pasta <-> hippo\", pasta.similarity(hippo))\n",
    "print(apple.has_vector, banana.has_vector, pasta.has_vector, hippo.has_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you‚Äôve been modifying the pipeline, vocabulary, vectors and entities\n",
    "#or made updates to the model, you‚Äôll eventually want to save your progress ‚Äì for example, everything that‚Äôs in your nlp object.\n",
    "# simple and efficient serialisation\n",
    "from spacy.tokens import Doc\n",
    "from spacy.vocab import Vocab\n",
    "customer_feedback = open(\"2019_08_Marvin1_without_labels_or_heading_orwidgets.txt\").read()\n",
    "doc = nlp(customer_feedback)\n",
    "doc.to_disk(\"2019_08_Marvin1_without_labels_or_heading_orwidgets.bin\")\n",
    "\n",
    "new_doc = Doc(Vocab()).from_disk(\"2019_08_Marvin1_without_labels_or_heading_orwidgets.bin\")\n",
    "print (new_doc[1:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minibatched stream processing\n",
    "texts = [\"One document.\", \"...\", \"Lots of documents\"]\n",
    "# .pipe streams input, and produces streaming output\n",
    "iter_texts = (texts[i % 3] for i in range(100000000))\n",
    "for i, doc in enumerate(nlp.pipe(iter_texts, batch_size=50)):\n",
    "    print (i,doc) # i added this in to show what can be done\n",
    "    assert doc.is_parsed\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advmod', 'advcl', 'compound', 'nsubj', 'advcl', 'nsubj', 'advcl', 'advcl', 'xcomp', 'advcl', 'prep', 'xcomp', 'advcl', 'npadvmod', 'amod', 'pobj', 'prep', 'xcomp', 'advcl', 'punct', 'amod', 'pobj', 'prep', 'xcomp', 'advcl', 'amod', 'pobj', 'prep', 'xcomp', 'advcl', 'pobj', 'prep', 'xcomp', 'advcl', 'prep', 'xcomp', 'advcl', 'pobj', 'prep', 'xcomp', 'advcl', 'prep', 'advcl', 'pobj', 'prep', 'advcl', 'punct', 'amod', 'nsubj', 'nsubj', 'prep', 'nsubj', 'prep', 'prep', 'nsubj', 'det', 'pobj', 'prep', 'prep', 'nsubj', 'pobj', 'prep', 'prep', 'nsubj', 'dobj', 'advmod', 'punct']\n"
     ]
    }
   ],
   "source": [
    "#syntactic dependencies\n",
    "doc = nlp(\"When Sebastian Thrun started working on self-driving cars at Google \"\n",
    "          \"in 2007, few people outside of the company took him seriously.\")\n",
    "dep_labels = []\n",
    "for token in doc:\n",
    "    while token.head != token:\n",
    "        dep_labels.append(token.dep_)\n",
    "        token = token.head\n",
    "print(dep_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 8104846059040039827 False\n",
      "out 1696981056005371314 False\n",
      "https://spacy.io 17142293684782158888 True\n",
      "(3, 2)\n",
      "3 2\n",
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#export to Numpy arrays\n",
    "from spacy.attrs import ORTH, LIKE_URL\n",
    "\n",
    "doc = nlp(\"Check out https://spacy.io\")\n",
    "for token in doc:\n",
    "    print(token.text, token.orth, token.like_url)\n",
    "\n",
    "attr_ids = [ORTH, LIKE_URL]\n",
    "doc_array = doc.to_array(attr_ids)\n",
    "print(doc_array.shape)\n",
    "print(len(doc), len(attr_ids))\n",
    "\n",
    "assert doc[0].orth == doc_array[0, 0]\n",
    "assert doc[1].orth == doc_array[1, 0]\n",
    "assert doc[0].like_url == doc_array[0, 1]\n",
    "\n",
    "assert list(doc_array[:, 1]) == [t.like_url for t in doc]\n",
    "print(list(doc_array[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
